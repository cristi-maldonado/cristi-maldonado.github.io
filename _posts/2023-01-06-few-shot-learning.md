---
layout: post
title: Few Shot Learning Intro. 
subtitle: Draft- Approaching Few Shot
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thinking.jpg
share-img: /assets/img/path.jpg
tags: [few shot learning, few, small sample]
author: Cristi Maldonado
---

Few Shot Learning has come riding in on a white horse to conteract the major limiation of large Natural Language Processing models. NLPs architectures can be used for various tasks, but in order for it to accomplish its specific task it needs a large dataset specific enough and fine-tuned to the task at hand. Labelling a large dataset is time-consuming at best and unattainable at worst. Few Shot learning comes in promising to deliver performance with just a few-shot demonstrations. The paper I reviewed was  [Language Models are Few Shot Learners.](https://arxiv.org/pdf/2005.14165.pdf/)
In this paper the GPT-3 model was discussed.  